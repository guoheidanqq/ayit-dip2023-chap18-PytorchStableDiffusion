{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import CLIPTokenizer\n",
    "import numpy as np\n",
    "from StableDiffusion.Utils import Utils\n",
    "import matplotlib.pyplot as plt\n",
    "import StableDiffusion.DdpmSamplerTorch\n",
    "import StableDiffusion.TimeEmbedding\n",
    "import StableDiffusion.Utils\n",
    "import StableDiffusion.UnetGlobalCrossAttentionBlock\n",
    "import StableDiffusion.UnetDenoise\n",
    "import StableDiffusion.LoraLayer\n",
    "import StableDiffusion.ClipEncoder\n",
    "import importlib\n",
    "importlib.reload(StableDiffusion.DdpmSamplerTorch)\n",
    "importlib.reload(StableDiffusion.TimeEmbedding)\n",
    "importlib.reload(StableDiffusion.Utils)\n",
    "importlib.reload(StableDiffusion.UnetGlobalCrossAttentionBlock)\n",
    "importlib.reload(StableDiffusion.UnetDenoise)\n",
    "importlib.reload(StableDiffusion.LoraLayer)\n",
    "importlib.reload(StableDiffusion.ClipEncoder)\n",
    "from StableDiffusion.DdpmSamplerTorch import DdpmSamplerTorch\n",
    "from StableDiffusion.TimeEmbedding import TimeEmbedding\n",
    "from StableDiffusion.Utils import Utils\n",
    "from StableDiffusion.UnetGlobalCrossAttentionBlock import UnetGlobalCrossAttentionBlock\n",
    "from StableDiffusion.UnetDenoise import UnetDenoise\n",
    "from StableDiffusion.ClipEncoder import ClipEncoder\n",
    "from StableDiffusion.LoraLayer import LoraLayer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "clipEncoder = ClipEncoder().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipLayersDict = dict(clipEncoder.named_modules())\n",
    "rawLinear = clipLayersDict['layers.11.attention.out_proj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora1 = LoraLayer(rawLinear,rank = 8,alpha =16)\n",
    "rawLinear.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoder'>\n",
      "Name: embedding | Type: <class 'StableDiffusion.ClipEncoder.ClipEmbedding'>\n",
      "Name: embedding.token_embedding | Type: <class 'torch.nn.modules.sparse.Embedding'>\n",
      "Name: layers | Type: <class 'torch.nn.modules.container.ModuleList'>\n",
      "Name: layers.0 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.0.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.0.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.0.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.0.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.0.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.0.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.0.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.1 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.1.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.1.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.1.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.1.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.1.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.1.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.1.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.2 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.2.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.2.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.2.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.2.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.2.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.2.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.2.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.3 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.3.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.3.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.3.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.3.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.3.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.3.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.3.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.4 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.4.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.4.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.4.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.4.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.4.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.4.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.4.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.5 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.5.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.5.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.5.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.5.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.5.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.5.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.5.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.6 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.6.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.6.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.6.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.6.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.6.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.6.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.6.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.7 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.7.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.7.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.7.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.7.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.7.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.7.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.7.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.8 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.8.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.8.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.8.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.8.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.8.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.8.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.8.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.9 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.9.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.9.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.9.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.9.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.9.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.9.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.9.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.10 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.10.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.10.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.10.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.10.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.10.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.10.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.10.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.11 | Type: <class 'StableDiffusion.ClipEncoder.ClipEncoderLayer'>\n",
      "Name: layers.11.layernorm_1 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.11.attention | Type: <class 'StableDiffusion.Attention.MHSelfAttention'>\n",
      "Name: layers.11.attention.in_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.11.attention.out_proj | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.11.layernorm_2 | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "Name: layers.11.linear_1 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layers.11.linear_2 | Type: <class 'torch.nn.modules.linear.Linear'>\n",
      "Name: layernorm | Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in clipEncoder.named_modules():\n",
    "    # 'name' is the string path (e.g., 'layers.0.self_attn.q_proj')\n",
    "    # 'module' is the actual layer object\n",
    "    print(f\"Name: {name} | Type: {type(module)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('MyEnvForSD': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "647a70d9ee79436e1ee2ec7ca1cc35c4dc1bf6626b891860add3bc52abf89db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
